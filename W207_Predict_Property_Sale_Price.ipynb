{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the Sale Price of a Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W207 Final Project\n",
    "#### Surya, Ian Anderson, Allison Godfrey, and Jackie Ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using machine learning approaches to try to most accurately predict home price based on relevant features. The goal of this notebook is to fully understand the data, extract the most relevant features, and apply different machine learning models with various regularization strengths to assess the accuracies, evaluate and compare the errors, and choose the best model accordingly. \n",
    "\n",
    "The components of our notebook are as follows: \n",
    "1. Exploratory Data Analysis \n",
    "2. Data Cleaning \n",
    "3. Feature Engineering\n",
    "4. Encoding Categorical Features\n",
    "5. Outlier Analysis\n",
    "6. Machine Learning Models and Assessment\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "#Set default matplotlib style to seaborn\n",
    "mpl.style.use('seaborn-darkgrid')\n",
    "base_color='#436BAD'\n",
    "red_color='#990000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "pd.options.display.width=None\n",
    "pd.options.display.max_columns = None\n",
    "#Train data\n",
    "train = pd.read_csv('./house-prices-data/train.csv',index_col=0)\n",
    "\n",
    "#Test data\n",
    "test = pd.read_csv('./house-prices-data/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data size\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data size\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Missing Values            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze on missing data\n",
    "# Missing values\n",
    "train_missing = train.isnull().sum()\n",
    "train_missing = pd.DataFrame(train_missing[train_missing > 0])\n",
    "train_missing.columns = ['Count']\n",
    "train_missing.sort_values(by='Count', ascending = False, inplace=True)\n",
    "train_missing['Percent'] = round((train_missing['Count'] /  len(train.index))* 100, 2) \n",
    "plt.figure(figsize=(15, 5))   \n",
    "plt.subplot(1,2, 1)\n",
    "print(train_missing)\n",
    "plt.bar(train_missing.index,train_missing['Count'],color=base_color)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Missing Values - Count')\n",
    "plt.subplot(1,2, 2)\n",
    "plt.bar(train_missing.index,train_missing['Percent'],color=base_color)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Missing Values - Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Jacky): Select 25 features and apply L1 analysys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Exclude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From section 2.1 there are 6 features above 10% NA. Let us drop them. Most of them are above 50% NA\n",
    "excluded_columns = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage']\n",
    "train_new= train.drop(excluded_columns, axis=1)\n",
    "test_new= test.drop(excluded_columns ,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2  Update Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical and Categorical (type=object) columns/features\n",
    "numerical_cols = train_new.select_dtypes(exclude=['object'])\n",
    "categorical_cols = train_new.select_dtypes(include=['object'])\n",
    "\n",
    "print('Numeric columns info')\n",
    "print('Total:', len(numerical_cols.columns))\n",
    "print('Column Names:', numerical_cols.columns)\n",
    "print('\\n')\n",
    "print('Categorical columns info')\n",
    "print('Total:', len(categorical_cols.columns))\n",
    "print('Column Names:', categorical_cols.columns)\n",
    "#fill missing object values with NA\n",
    "for col in list(categorical_cols.columns):\n",
    "    train_new[col].fillna('NA', inplace=True)  \n",
    "    if (col != 'SalePrice'):\n",
    "        test_new[col].fillna('NA', inplace=True)\n",
    "    \n",
    "#fill missing numerical values with 0\n",
    "for col in list(numerical_cols.columns):\n",
    "    train_new[col].fillna(0, inplace=True)\n",
    "    if (col != 'SalePrice'):\n",
    "        test_new[col].fillna(0, inplace=True)\n",
    "\n",
    "#Re-initialize the columns with updated data\n",
    "numerical_cols = train_new.select_dtypes(exclude=['object'])\n",
    "categorical_cols = train_new.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TODO: Do some analysys on Categorical columns .... come up with a paragraph on what our understanding is...\n",
    "(Ian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3  Features with Highest Correlation with Sales Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's Rank\n",
    "spearman_rank = pd.DataFrame()\n",
    "spearman_rank['Feature'] = train_new.columns\n",
    "spearman_rank['Spearman Rank'] = [train_new[f].corr(train_new['SalePrice'], 'spearman') for f in train_new.columns]\n",
    "spearman_rank = spearman_rank.sort_values('Spearman Rank')\n",
    "    \n",
    "plt.figure(figsize=(6, 0.25*len(train_new.columns)))\n",
    "sns.barplot(data=spearman_rank, y='Feature', x='Spearman Rank', orient='h', palette=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat Map for largest 25 features\n",
    "corr_matrix = train_new.corr()\n",
    "high_corr_cols = corr_matrix.nlargest(26, 'SalePrice')['SalePrice'].index # Add 1 as it includes SalePrice\n",
    "cm = np.corrcoef(train_new[high_corr_cols].values.T)\n",
    "sns.set(font_scale=1.1)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "hm = sns.heatmap(cm,annot=True, square=True, fmt='.2f', \n",
    "                 annot_kws={'size': 10}, yticklabels=high_corr_cols.values, \n",
    "                 xticklabels=high_corr_cols.values, ax = ax, cmap=\"Blues\", linewidths=1, \n",
    "                 linecolor=base_color, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Based on Heat Map and Spearman's Rank...... analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show the distribution plots for numerical features.\n",
    "fig, axes = plt.subplots(figsize=(20,30))\n",
    "fig.tight_layout()\n",
    "cell_no = 1\n",
    "for column_name in numerical_cols.columns:     \n",
    "    plt.subplot(9, 4, cell_no)\n",
    "    sns.distplot(numerical_cols[column_name], hist=True, kde=True, \n",
    "                 hist_kws = {'color':base_color, 'alpha':0.9},  \n",
    "                 kde_kws = {'color':red_color, 'alpha':0.9},label=column_name)\n",
    "    cell_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "TODO: Provide analysis (Surya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Analysis on 'Sale Price' (Outcome / Dependent / Target) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the Sale Price distribution\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.distplot(train_new['SalePrice'], hist=True, kde=True, \n",
    "                 hist_kws = {'color':base_color, 'alpha':0.9},  \n",
    "                 kde_kws = {'color':red_color, 'alpha':0.9});\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.title(\"Distribution\")\n",
    "stats.probplot(train['SalePrice'], plot=ax2);\n",
    "ax2.get_lines()[0].set_color(base_color)\n",
    "ax2.get_lines()[1].set_color(red_color)\n",
    "plt.title(\"Probability Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Provide analysys on right skewed distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply log transformation to SalePrice Outcome variable\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.distplot(np.log(train_new['SalePrice']),   hist=True, kde=True, \n",
    "                 hist_kws = {'color':base_color, 'alpha':0.9},  \n",
    "                 kde_kws = {'color':red_color, 'alpha':0.9})\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.title(\"Distribution after Log transformation\")\n",
    "stats.probplot(np.log(train_new['SalePrice']), plot=ax2);\n",
    "ax2.get_lines()[0].set_color(base_color)\n",
    "ax2.get_lines()[1].set_color(red_color)\n",
    "plt.title(\"Probability after Log transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Provide analysys on normal distribution after log transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5    Target feature ('Sales Price') and Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "n = 1\n",
    "for col in numerical_cols.columns:  \n",
    "    scatter = plt.subplot(6, 6, n)\n",
    "    plt.scatter(train_new[col], train_new[\"SalePrice\"], color = 'b')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Sale Price\")\n",
    "    n+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Analysys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6   Exclude Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: For the selected features, drop the Outliers with certain conditions.\n",
    "# (Ian) - Summary statistics and box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7  Create Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Split the Train Data into Train(80%) and Dev Data (20%) for model building\n",
    "# Label will be the SalePrice column data. We can even randamize the initial 80% split if possible.\n",
    "\n",
    "#Output should be train_data, train_labels, dev_data, dev_labels. No change to test_data. \n",
    "# (Jacky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### L1 Analysus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Run each model with different L1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Linear Regression      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 KNN Regression   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Gradient Boosting   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Support Vector Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO This is from Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 XGBoost Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Models comparison (RMSE comparison between models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO We can provide some sort of simple bar chart showing different R squared values of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
